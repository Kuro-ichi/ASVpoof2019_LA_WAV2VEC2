{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install soundfile\n\n# %%\nimport os, sys, math, random, time, json, gc\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nimport torchaudio\nimport torchaudio.transforms as T\n\nfrom sklearn.metrics import roc_curve, accuracy_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:12.497649Z","iopub.execute_input":"2025-11-10T19:47:12.498475Z","iopub.status.idle":"2025-11-10T19:47:19.956234Z","shell.execute_reply.started":"2025-11-10T19:47:12.498436Z","shell.execute_reply":"2025-11-10T19:47:19.955381Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"SEED = 1337\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.benchmark = True\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nDATA_ROOT = Path('/kaggle/input/asvpoof-2019-dataset/LA/LA')\n\n# Protocol files (chuẩn ASVspoof2019 LA)\nPROTO_DIR = DATA_ROOT / 'ASVspoof2019_LA_cm_protocols'\nTRAIN_PROTO = PROTO_DIR / 'ASVspoof2019.LA.cm.train.trn.txt'\nDEV_PROTO   = PROTO_DIR / 'ASVspoof2019.LA.cm.dev.trl.txt'\nEVAL_PROTO  = PROTO_DIR / 'ASVspoof2019.LA.cm.eval.trl.txt'\n\n# Audio dirs\nTRAIN_AUDIO_DIR = DATA_ROOT / 'ASVspoof2019_LA_train'\nDEV_AUDIO_DIR   = DATA_ROOT / 'ASVspoof2019_LA_dev'\nEVAL_AUDIO_DIR  = DATA_ROOT / 'ASVspoof2019_LA_eval'\n\n# Tập tin audio thường nằm trong subfolder 'flac' theo layout chuẩn\ndef with_flac_dir(p: Path) -> Path:\n    return p / 'flac' if (p / 'flac').exists() else p\n\nTRAIN_AUDIO_DIR = with_flac_dir(TRAIN_AUDIO_DIR)\nDEV_AUDIO_DIR   = with_flac_dir(DEV_AUDIO_DIR)\nEVAL_AUDIO_DIR  = with_flac_dir(EVAL_AUDIO_DIR)\n\nSAMPLE_RATE = 16_000\nTARGET_SEC = 4.0\nTARGET_SAMPLES = int(TARGET_SEC * SAMPLE_RATE)\n\n# Feature config cho log-Mel\nN_MELS = 80\nN_FFT = 1024\nHOP_LENGTH = 160\nWIN_LENGTH = 400\n\n# Huấn luyện\nBATCH_SIZE = 32\nLR = 2e-4\nEPOCHS = 12  # có thể tăng 20-30 để tối ưu EER\nWEIGHT_DECAY = 1e-4\nGRAD_CLIP = 5.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:19.957623Z","iopub.execute_input":"2025-11-10T19:47:19.957949Z","iopub.status.idle":"2025-11-10T19:47:20.061131Z","shell.execute_reply.started":"2025-11-10T19:47:19.957928Z","shell.execute_reply":"2025-11-10T19:47:20.060452Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# # 2) Protocol → DataFrame\n# Format chuẩn: speaker_id, utterance_id, system_id, key (bonafide/spoof)\n# File audio: {split}/flac/{utterance_id}.flac\n\ndef parse_protocol(proto_path: Path, split: str, audio_root: Path):\n    rows = []\n    with open(proto_path, 'r') as f:\n        for line in f:\n            if not line.strip() or line.startswith('#'):\n                continue\n            parts = line.strip().split()\n            # Hỗ trợ cả format 4-5 cột\n            # thường là: speaker_id, utt_id, _, sys_id, key  hoặc  speaker_id, utt_id, sys_id, key\n            speaker_id = parts[0]\n            utt_id = parts[1]\n            sys_id = parts[-2]\n            key = parts[-1]\n            label = 1 if key.lower() == 'spoof' else 0  # positive=spoof cho EER ROC\n            audio_path = audio_root / f\"{utt_id}.flac\"\n            rows.append({\n                'split': split,\n                'speaker_id': speaker_id,\n                'utt_id': utt_id,\n                'sys_id': sys_id,\n                'key': key.lower(),\n                'label': label,\n                'path': str(audio_path)\n            })\n    return pd.DataFrame(rows)\n\ntrain_df = parse_protocol(TRAIN_PROTO, 'train', TRAIN_AUDIO_DIR)\ndev_df   = parse_protocol(DEV_PROTO, 'dev', DEV_AUDIO_DIR)\neval_df  = parse_protocol(EVAL_PROTO, 'eval', EVAL_AUDIO_DIR)\n\nprint(train_df.head(), '\\n', dev_df.head(), '\\n', eval_df.head())\nprint('Counts:', train_df.key.value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:20.061836Z","iopub.execute_input":"2025-11-10T19:47:20.062113Z","iopub.status.idle":"2025-11-10T19:47:20.827097Z","shell.execute_reply.started":"2025-11-10T19:47:20.062081Z","shell.execute_reply":"2025-11-10T19:47:20.826315Z"}},"outputs":[{"name":"stdout","text":"   split speaker_id        utt_id sys_id       key  label  \\\n0  train    LA_0079  LA_T_1138215      -  bonafide      0   \n1  train    LA_0079  LA_T_1271820      -  bonafide      0   \n2  train    LA_0079  LA_T_1272637      -  bonafide      0   \n3  train    LA_0079  LA_T_1276960      -  bonafide      0   \n4  train    LA_0079  LA_T_1341447      -  bonafide      0   \n\n                                                path  \n0  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n1  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n2  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n3  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n4  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...   \n   split speaker_id        utt_id sys_id       key  label  \\\n0   dev    LA_0069  LA_D_1047731      -  bonafide      0   \n1   dev    LA_0069  LA_D_1105538      -  bonafide      0   \n2   dev    LA_0069  LA_D_1125976      -  bonafide      0   \n3   dev    LA_0069  LA_D_1293230      -  bonafide      0   \n4   dev    LA_0069  LA_D_1340209      -  bonafide      0   \n\n                                                path  \n0  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n1  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n2  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n3  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n4  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...   \n   split speaker_id        utt_id sys_id    key  label  \\\n0  eval    LA_0039  LA_E_2834763    A11  spoof      1   \n1  eval    LA_0014  LA_E_8877452    A14  spoof      1   \n2  eval    LA_0040  LA_E_6828287    A16  spoof      1   \n3  eval    LA_0022  LA_E_6977360    A09  spoof      1   \n4  eval    LA_0031  LA_E_5932896    A13  spoof      1   \n\n                                                path  \n0  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n1  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n2  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n3  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \n4  /kaggle/input/asvpoof-2019-dataset/LA/LA/ASVsp...  \nCounts: key\nspoof       22800\nbonafide     2580\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# # 3) Dataset/Dataloader\n# - Đọc .flac bằng torchaudio, resample về 16k nếu cần\n# - Chuẩn hoá gain, crop/pad về 4s\n# - Tạo log-Mel cho nhánh SPEC\n# - Augment nhẹ: gain jitter, noise rất nhỏ, SpecAugment\n\n# %%\nresampler = T.Resample(orig_freq=SAMPLE_RATE, new_freq=SAMPLE_RATE)  # no-op nếu đã 16k\nmel_extractor = T.MelSpectrogram(\n    sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH,\n    f_min=20, f_max=7600, n_mels=N_MELS, center=True, power=2.0\n)\namplitude_to_db = T.AmplitudeToDB(stype='power')\n\n# SpecAugment (nhẹ)\nspec_time_mask = T.TimeMasking(time_mask_param=20)\nspec_freq_mask = T.FrequencyMasking(freq_mask_param=8)\n\ndef pre_emphasis(wav, coeff=0.97):\n    # wav: (T,)\n    y = torch.clone(wav)\n    y[1:] = wav[1:] - coeff * wav[:-1]\n    return y\n\ndef crop_or_pad(wav, target_len=TARGET_SAMPLES):\n    L = wav.shape[-1]\n    if L > target_len:\n        start = random.randint(0, L - target_len)\n        return wav[:, start:start+target_len]\n    elif L < target_len:\n        # lặp/zero-pad về đúng độ dài\n        repeat = (target_len // L) + 1\n        wav = wav.repeat(1, repeat)[:, :target_len]\n        return wav\n    else:\n        return wav\n\nclass LA19Dataset(Dataset):\n    def __init__(self, df: pd.DataFrame, training: bool):\n        self.df = df.reset_index(drop=True)\n        self.training = training\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        path = row['path']\n        wav, sr = torchaudio.load(path)  # (C, T)\n        if wav.shape[0] > 1:\n            wav = wav.mean(dim=0, keepdim=True)\n        if sr != SAMPLE_RATE:\n            wav = resampler(wav)\n        wav = wav / (wav.abs().max() + 1e-9)\n\n        if self.training:\n            # Gain jitter nhỏ\n            gain = 10 ** (random.uniform(-1.0, 1.0) / 20)\n            wav = wav * gain\n        # Pre-emphasis\n        wav = pre_emphasis(wav.squeeze(0)).unsqueeze(0)\n        # Crop/Pad\n        wav = crop_or_pad(wav, TARGET_SAMPLES)\n\n        # Log-Mel\n        with torch.no_grad():\n            mel = mel_extractor(wav)  # (1, n_mels, Tm)\n            mel = amplitude_to_db(mel)\n            if self.training:\n                mel = spec_freq_mask(spec_time_mask(mel))\n\n        label = row['label'] if row['split'] != 'eval' else -1\n        return {\n            'wav': wav,             # (1, T)\n            'mel': mel,             # (1, M, Tm)\n            'label': label,\n            'utt_id': row['utt_id'],\n            'sys_id': row['sys_id']\n        }\n\n# Sampler có trọng số để cân bằng spoof/bonafide\ncls_counts = train_df['label'].value_counts().to_dict()\npos_w = 1.0 / cls_counts.get(1,1)\nneg_w = 1.0 / cls_counts.get(0,1)\nweights = train_df['label'].map({1: pos_w, 0: neg_w}).values\nsampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n\ntrain_ds = LA19Dataset(train_df, training=True)\ndev_ds   = LA19Dataset(dev_df,   training=False)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n                          num_workers=2, pin_memory=True, drop_last=True)\ndev_loader   = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=2, pin_memory=True, drop_last=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:20.827957Z","iopub.execute_input":"2025-11-10T19:47:20.828356Z","iopub.status.idle":"2025-11-10T19:47:20.940691Z","shell.execute_reply.started":"2025-11-10T19:47:20.828328Z","shell.execute_reply":"2025-11-10T19:47:20.939924Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# # 4) Mô hình DRSAS‑Net \n# - Nhánh RAW: Res1D + SE\n# - Nhánh SPEC: DS-Conv2D + SE\n# - Fusion bằng gating attention\n# - Head nhị phân: output logit (spoof score)\n\nclass SE1D(nn.Module):\n    def __init__(self, c, r=8):\n        super().__init__()\n        self.fc1 = nn.Conv1d(c, c//r, 1)\n        self.fc2 = nn.Conv1d(c//r, c, 1)\n    def forward(self, x):\n        w = x.mean(-1, keepdim=True)\n        w = F.relu(self.fc1(w))\n        w = torch.sigmoid(self.fc2(w))\n        return x * w\n\nclass ResBlock1D(nn.Module):\n    def __init__(self, c, k=5, d=1):\n        super().__init__()\n        pad = (k//2) * d\n        self.conv1 = nn.Conv1d(c, c, k, padding=pad, dilation=d, bias=False)\n        self.bn1 = nn.BatchNorm1d(c)\n        self.conv2 = nn.Conv1d(c, c, k, padding=pad, dilation=d, bias=False)\n        self.bn2 = nn.BatchNorm1d(c)\n        self.se = SE1D(c)\n        self.act = nn.PReLU(c)\n    def forward(self, x):\n        r = x\n        x = self.act(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        x = self.se(x) + r\n        x = self.act(x)\n        return x\n\nclass RAWBranch(nn.Module):\n    def __init__(self, emb_dim=256):\n        super().__init__()\n        self.stem = nn.Sequential(\n            nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm1d(64),\n            nn.PReLU(64),\n        )\n        self.layer1 = ResBlock1D(64, k=5, d=1)\n        self.down1  = nn.Conv1d(64, 128, 3, stride=2, padding=1)\n        self.layer2 = ResBlock1D(128, k=5, d=2)\n        self.down2  = nn.Conv1d(128, 192, 3, stride=2, padding=1)\n        self.layer3 = ResBlock1D(192, k=3, d=3)\n        self.pool   = nn.AdaptiveAvgPool1d(1)\n        self.fc     = nn.Linear(192, emb_dim)\n\n    def forward(self, wav):  # (B, 1, T)\n        x = self.stem(wav)\n        x = self.layer1(x)\n        x = self.down1(x)\n        x = self.layer2(x)\n        x = self.down2(x)\n        x = self.layer3(x)\n        x = self.pool(x).squeeze(-1)   # (B, C)\n        e = self.fc(x)\n        return e\n\nclass SE2D(nn.Module):\n    def __init__(self, c, r=8):\n        super().__init__()\n        self.fc1 = nn.Conv2d(c, c//r, 1)\n        self.fc2 = nn.Conv2d(c//r, c, 1)\n    def forward(self, x):\n        w = x.mean((-2,-1), keepdim=True)\n        w = F.relu(self.fc1(w))\n        w = torch.sigmoid(self.fc2(w))\n        return x * w\n\nclass DSConv2dBlock(nn.Module):\n    def __init__(self, c_in, c_out, stride=1):\n        super().__init__()\n        self.dw = nn.Conv2d(c_in, c_in, 3, stride=stride, padding=1, groups=c_in, bias=False)\n        self.pw = nn.Conv2d(c_in, c_out, 1, bias=False)\n        self.bn = nn.BatchNorm2d(c_out)\n        self.act = nn.PReLU(c_out)\n        self.se = SE2D(c_out)\n        self.skip = None\n        if stride != 1 or c_in != c_out:\n            self.skip = nn.Sequential(\n                nn.Conv2d(c_in, c_out, 1, stride=stride, bias=False),\n                nn.BatchNorm2d(c_out)\n            )\n    def forward(self, x):\n        r = x if self.skip is None else self.skip(x)\n        x = self.dw(x)\n        x = self.pw(x)\n        x = self.bn(x)\n        x = self.se(x)\n        x = self.act(x + r)\n        return x\n\nclass SPECBranch(nn.Module):\n    def __init__(self, emb_dim=256):\n        super().__init__()\n        self.stem = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.PReLU(32)\n        )\n        self.b1 = DSConv2dBlock(32, 64, stride=2)\n        self.b2 = DSConv2dBlock(64, 96, stride=2)\n        self.b3 = DSConv2dBlock(96, 128, stride=2)\n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(128, emb_dim)\n\n    def forward(self, mel):  # (B, 1, M, Tm)\n        x = self.stem(mel)\n        x = self.b1(x)\n        x = self.b2(x)\n        x = self.b3(x)\n        x = self.pool(x).flatten(1)\n        e = self.fc(x)\n        return e\n\nclass DRSASNet(nn.Module):\n    def __init__(self, emb_dim=256, dropout=0.2):\n        super().__init__()\n        self.raw = RAWBranch(emb_dim)\n        self.spec = SPECBranch(emb_dim)\n        self.fuse_gate = nn.Sequential(\n            nn.Linear(emb_dim*2, emb_dim),\n            nn.PReLU(emb_dim),\n            nn.Linear(emb_dim, 2),   # 2 logit -> softmax -> gate cho [raw, spec]\n        )\n        self.head = nn.Sequential(\n            nn.Linear(emb_dim, emb_dim//2),\n            nn.PReLU(emb_dim//2),\n            nn.Dropout(dropout),\n            nn.Linear(emb_dim//2, 1) # logit spoof\n        )\n\n    def forward(self, wav, mel):\n        e_raw = self.raw(wav)              # (B, D)\n        e_spec = self.spec(mel)            # (B, D)\n        z = torch.cat([e_raw, e_spec], dim=1)\n        g = F.softmax(self.fuse_gate(z), dim=1)  # (B,2)\n        fused = g[:,0:1]*e_raw + g[:,1:2]*e_spec\n        logit = self.head(fused).squeeze(1)\n        return logit, fused, g\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:20.942154Z","iopub.execute_input":"2025-11-10T19:47:20.942347Z","iopub.status.idle":"2025-11-10T19:47:20.960953Z","shell.execute_reply.started":"2025-11-10T19:47:20.942331Z","shell.execute_reply":"2025-11-10T19:47:20.960123Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# %% [markdown]\n# # 5) Vòng lặp train + EER\n# - Loss: BCEWithLogitsLoss với pos_weight để cân bằng class (positive=spoof)\n# - AMP + gradient clip\n# - Đánh giá EER/ACC trên dev sau mỗi epoch, lưu best model\n\n# %%\ndef compute_eer(y_true, scores):\n    # y_true: 1=spoof (positive), 0=bonafide\n    fpr, tpr, th = roc_curve(y_true, scores, pos_label=1)\n    fnr = 1 - tpr\n    idx = np.nanargmin(np.abs(fnr - fpr))\n    eer = (fnr[idx] + fpr[idx]) / 2.0\n    return float(eer*100), float(th[idx])\n\nmodel = DRSASNet().to(DEVICE)\n\n# pos_weight: tỷ lệ bonafide/spoof để cân bằng; ở LA train, spoof thường nhiều hơn\nnum_pos = train_df['label'].sum()\nnum_neg = len(train_df) - num_pos\npos_weight = torch.tensor([ (num_neg + 1e-6) / (num_pos + 1e-6) ], device=DEVICE)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR/50)\n\nscaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n\nbest_eer = 1e9\nbest_path = '/kaggle/working/drsasnet_best.pt'\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    tr_loss = 0.0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n    for batch in pbar:\n        wav = batch['wav'].to(DEVICE)      # (B, 1, T)\n        mel = batch['mel'].to(DEVICE)      # (B, 1, M, Tm)\n        y = batch['label'].float().to(DEVICE)\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n            logit, _, _ = model(wav, mel)\n            loss = criterion(logit, y)\n        scaler.scale(loss).backward()\n        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n        scaler.step(optimizer)\n        scaler.update()\n        tr_loss += loss.item()\n        pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{scheduler.get_last_lr()[0]:.2e}\")\n    scheduler.step()\n\n    # Evaluate\n    model.eval()\n    all_scores, all_labels = [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            wav = batch['wav'].to(DEVICE)\n            mel = batch['mel'].to(DEVICE)\n            logit, _, _ = model(wav, mel)\n            score = torch.sigmoid(logit).detach().cpu().numpy()  # spoof probability\n            all_scores.extend(score.tolist())\n            all_labels.extend(batch['label'].numpy().tolist())\n    eer, th = compute_eer(np.array(all_labels), np.array(all_scores))\n    preds = (np.array(all_scores) >= 0.5).astype(int)\n    acc = accuracy_score(all_labels, preds) * 100.0\n\n    print(f\"[Epoch {epoch}] train_loss={tr_loss/len(train_loader):.4f} | DEV: EER={eer:.3f}% @th={th:.3f} | ACC={acc:.2f}%\")\n\n    if eer < best_eer:\n        best_eer = eer\n        torch.save({'model': model.state_dict(),\n                    'eer': best_eer,\n                    'threshold_eer': th}, best_path)\n        print(f\"  ↳ Saved best to {best_path} (EER={best_eer:.3f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:47:20.961727Z","iopub.execute_input":"2025-11-10T19:47:20.961967Z","iopub.status.idle":"2025-11-10T21:08:32.878010Z","shell.execute_reply.started":"2025-11-10T19:47:20.961944Z","shell.execute_reply":"2025-11-10T21:08:32.877040Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_48/3061398193.py:27: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\nEpoch 1/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 1/12: 100%|██████████| 793/793 [04:05<00:00,  3.23it/s, loss=0.0430, lr=2.00e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] train_loss=0.1231 | DEV: EER=14.834% @th=0.096 | ACC=77.73%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=14.834%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 2/12: 100%|██████████| 793/793 [04:09<00:00,  3.18it/s, loss=0.0585, lr=1.97e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] train_loss=0.0849 | DEV: EER=13.328% @th=0.048 | ACC=78.78%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=13.328%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 3/12: 100%|██████████| 793/793 [04:11<00:00,  3.15it/s, loss=0.0362, lr=1.87e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] train_loss=0.0698 | DEV: EER=11.946% @th=0.039 | ACC=78.81%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=11.946%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 4/12: 100%|██████████| 793/793 [04:21<00:00,  3.04it/s, loss=0.0362, lr=1.71e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] train_loss=0.0662 | DEV: EER=7.643% @th=0.201 | ACC=89.06%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=7.643%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 5/12: 100%|██████████| 793/793 [04:29<00:00,  2.94it/s, loss=0.0426, lr=1.51e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] train_loss=0.0546 | DEV: EER=2.874% @th=0.938 | ACC=97.89%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=2.874%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 6/12: 100%|██████████| 793/793 [04:18<00:00,  3.07it/s, loss=0.0000, lr=1.27e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] train_loss=0.0397 | DEV: EER=2.507% @th=0.000 | ACC=50.63%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=2.507%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 7/12: 100%|██████████| 793/793 [04:04<00:00,  3.25it/s, loss=0.0000, lr=1.02e-04]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] train_loss=0.0108 | DEV: EER=0.893% @th=1.000 | ACC=99.13%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=0.893%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 8/12: 100%|██████████| 793/793 [03:58<00:00,  3.32it/s, loss=0.0000, lr=7.66e-05]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] train_loss=0.0080 | DEV: EER=0.309% @th=1.000 | ACC=99.90%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=0.309%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 9/12: 100%|██████████| 793/793 [03:55<00:00,  3.36it/s, loss=0.0000, lr=5.30e-05]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] train_loss=0.0013 | DEV: EER=0.029% @th=0.966 | ACC=99.98%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=0.029%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 10/12: 100%|██████████| 793/793 [03:54<00:00,  3.38it/s, loss=0.0000, lr=3.27e-05]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] train_loss=0.0011 | DEV: EER=0.031% @th=0.989 | ACC=99.99%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 11/12: 100%|██████████| 793/793 [03:53<00:00,  3.40it/s, loss=0.0000, lr=1.71e-05]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] train_loss=0.0004 | DEV: EER=0.084% @th=1.000 | ACC=99.98%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/12:   0%|          | 0/793 [00:00<?, ?it/s]/tmp/ipykernel_48/3061398193.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 12/12: 100%|██████████| 793/793 [03:53<00:00,  3.40it/s, loss=0.0000, lr=7.34e-06]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] train_loss=0.0001 | DEV: EER=0.024% @th=0.950 | ACC=99.98%\n  ↳ Saved best to /kaggle/working/drsasnet_best.pt (EER=0.024%)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# %% [markdown]\n# # 6) Đánh giá cuối cùng (dùng best checkpoint)\n\n# %%\nckpt = torch.load('/kaggle/working/drsasnet_best.pt', map_location='cpu')\nmodel.load_state_dict(ckpt['model'])\nthreshold_eer = ckpt.get('threshold_eer', 0.5)\nbest_eer = ckpt.get('eer', None)\nprint('Best EER (dev):', best_eer, 'Threshold@EER:', threshold_eer)\n\n# Tính ACC tại ngưỡng EER\nmodel.eval()\nscores, labels = [], []\nwith torch.no_grad():\n    for batch in dev_loader:\n        wav = batch['wav'].to(DEVICE)\n        mel = batch['mel'].to(DEVICE)\n        logit, _, _ = model(wav, mel)\n        prob = torch.sigmoid(logit).cpu().numpy()\n        scores.extend(prob.tolist())\n        labels.extend(batch['label'].numpy().tolist())\n\ny_true = np.array(labels)\ny_score = np.array(scores)\neer, th = compute_eer(y_true, y_score)\ny_pred = (y_score >= th).astype(int)  # positive=spoof\nacc = accuracy_score(y_true, y_pred)*100\nprint(f\"DEV summary → EER={eer:.3f}% @th={th:.3f} | ACC={acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:09:31.550497Z","iopub.execute_input":"2025-11-10T21:09:31.551161Z","iopub.status.idle":"2025-11-10T21:12:11.675753Z","shell.execute_reply.started":"2025-11-10T21:09:31.551129Z","shell.execute_reply":"2025-11-10T21:12:11.674851Z"}},"outputs":[{"name":"stdout","text":"Best EER (dev): 0.02410834334561755 Threshold@EER: 0.9496035575866699\nDEV summary → EER=0.004% @th=0.998 | ACC=99.99%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# %% [markdown]\n# ## 8) Full EVAL scoring → CSV\n# - Dùng DRSASNet đã train\n# - Xuất spoof probability cho từng utt_id\n\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport torch, numpy as np\n\ntry:\n    eval_df\nexcept NameError:\n    # Nếu bạn đã có parse_protocol ở trên\n    PROTO_DIR = DATA_ROOT / 'ASVspoof2019_LA_cm_protocols'\n    EVAL_PROTO  = PROTO_DIR / 'ASVspoof2019.LA.cm.eval.trl.txt'\n    EVAL_AUDIO_DIR  = (DATA_ROOT / 'ASVspoof2019_LA_eval' / 'flac'\n                       if (DATA_ROOT / 'ASVspoof2019_LA_eval' / 'flac').exists()\n                       else DATA_ROOT / 'ASVspoof2019_LA_eval')\n    eval_df  = parse_protocol(EVAL_PROTO, 'eval', EVAL_AUDIO_DIR)\n\n# Dataloader cho eval\neval_ds = LA19Dataset(eval_df, training=False)\neval_loader = DataLoader(eval_ds, batch_size=BATCH_SIZE, shuffle=False,\n                         num_workers=min(8, os.cpu_count() or 2),\n                         pin_memory=True, persistent_workers=True)\n\n# Load best checkpoint nếu cần\nbest_path = '/kaggle/working/drsasnet_best.pt'\nif Path(best_path).exists():\n    ckpt = torch.load(best_path, map_location='cpu')\n    model.load_state_dict(ckpt['model'])\nmodel.to(DEVICE).eval()\n\n# Chấm điểm\nutt_ids, scores = [], []\nwith torch.no_grad():\n    for batch in tqdm(eval_loader, desc='Scoring EVAL'):\n        wav = batch['wav'].to(DEVICE, non_blocking=True)\n        mel = batch['mel'].to(DEVICE, non_blocking=True)\n        logit, _, _ = model(wav, mel)\n        prob = torch.sigmoid(logit).float().cpu().numpy()\n        utt_ids.extend(batch['utt_id'])\n        scores.extend(prob.tolist())\n\neval_scores = pd.DataFrame({'utt_id': utt_ids, 'cm_score': scores})\nsave_path = '/kaggle/working/drsasnet_eval_scores.csv'\neval_scores.to_csv(save_path, index=False)\nprint(f'✔ Saved: {save_path}')\neval_scores.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:39:52.784731Z","iopub.execute_input":"2025-11-10T21:39:52.785017Z","iopub.status.idle":"2025-11-10T21:47:26.871767Z","shell.execute_reply.started":"2025-11-10T21:39:52.784962Z","shell.execute_reply":"2025-11-10T21:47:26.870536Z"}},"outputs":[{"name":"stderr","text":"Scoring EVAL: 100%|██████████| 2227/2227 [07:33<00:00,  4.91it/s]","output_type":"stream"},{"name":"stdout","text":"✔ Saved: /kaggle/working/drsasnet_eval_scores.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"         utt_id  cm_score\n0  LA_E_2834763  0.999998\n1  LA_E_8877452  1.000000\n2  LA_E_6828287  1.000000\n3  LA_E_6977360  1.000000\n4  LA_E_5932896  1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utt_id</th>\n      <th>cm_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LA_E_2834763</td>\n      <td>0.999998</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LA_E_8877452</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LA_E_6828287</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LA_E_6977360</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LA_E_5932896</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}